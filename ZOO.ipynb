{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:12:59.050349Z",
     "start_time": "2023-11-17T08:12:55.719239500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tc.tc_fc import TTLinear\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import tntorch as tn\n",
    "from pytorch_minimize.optim import MinimizeWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:13:08.634633Z",
     "start_time": "2023-11-17T08:13:08.620632600Z"
    }
   },
   "id": "2e08e1051dc4091"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "hid = [5, 2, 5, 2]\n",
    "rank = [1, 2, 2, 2, 1]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "        nn.Linear(2, 100),\n",
    "        nn.Tanh(),\n",
    "        TTLinear(hid, hid, rank, activation=None),\n",
    "        nn.Tanh(),\n",
    "        TTLinear(hid, hid, rank, activation=None),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(100, 1)).to(device)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:13:08.938362700Z",
     "start_time": "2023-11-17T08:13:08.923584100Z"
    }
   },
   "id": "f6b7cd9513269a1a"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('b', tensor([1.])),\n             ('W_cores.0', tensor([[[[-0.5346,  0.5896],\n                        [ 0.3231, -0.4545],\n                        [ 0.0695, -0.0094],\n                        [-0.0131, -0.0202],\n                        [ 0.2038,  0.8469]],\n              \n                       [[ 0.4613,  0.2683],\n                        [-0.3998, -0.5913],\n                        [ 0.0253,  0.0046],\n                        [ 0.1612,  0.5893],\n                        [ 0.8060, -0.3599]],\n              \n                       [[-0.0447, -0.2268],\n                        [-0.1123, -0.4232],\n                        [ 1.1072, -0.0714],\n                        [ 0.1988, -0.0288],\n                        [-0.1353,  0.2569]],\n              \n                       [[-0.5316, -0.0047],\n                        [-0.1453, -0.1965],\n                        [-0.0384, -0.3857],\n                        [-0.3401, -0.3599],\n                        [-0.4302, -0.4828]],\n              \n                       [[ 0.0907,  0.4655],\n                        [ 0.4973,  0.3311],\n                        [ 0.0981, -0.8368],\n                        [-0.0555, -0.2943],\n                        [ 0.1787,  0.4494]]]])),\n             ('W_cores.1',\n              tensor([[[[ 0.1260, -0.3261],\n                        [-0.5995, -0.6359]],\n              \n                       [[ 0.0065, -0.1476],\n                        [ 0.1733,  0.0410]]],\n              \n              \n                      [[[ 0.7703, -0.0998],\n                        [-0.3078, -0.4930]],\n              \n                       [[ 0.2070, -0.0163],\n                        [-0.2499, -0.7105]]]])),\n             ('W_cores.2',\n              tensor([[[[-0.2040, -0.4941],\n                        [ 0.3781,  0.1402],\n                        [-0.0705,  0.0345],\n                        [ 0.6108, -0.6193],\n                        [-0.0711, -0.7754]],\n              \n                       [[ 0.2035,  0.0542],\n                        [ 0.7360,  0.4795],\n                        [ 0.1114, -0.3307],\n                        [-0.4550, -0.1845],\n                        [-0.1649,  0.5409]],\n              \n                       [[-0.3253, -0.4612],\n                        [-0.0238,  0.7132],\n                        [ 0.1580, -0.3896],\n                        [ 0.4652, -0.4630],\n                        [-0.1901, -0.2693]],\n              \n                       [[-0.4774,  0.0071],\n                        [ 0.6621,  0.7192],\n                        [-0.6817,  0.8077],\n                        [-0.1935,  0.8190],\n                        [ 0.5573,  0.0676]],\n              \n                       [[-0.2040, -0.5958],\n                        [ 0.3735, -0.0493],\n                        [-0.0388, -0.5870],\n                        [ 0.2126,  0.0146],\n                        [-0.6192, -0.5078]]],\n              \n              \n                      [[[ 0.1163,  0.2087],\n                        [ 0.4404,  0.4940],\n                        [ 0.0800,  0.3488],\n                        [-0.0113,  0.0020],\n                        [ 0.1266, -0.2229]],\n              \n                       [[ 0.6131, -0.6311],\n                        [ 0.2049,  0.0071],\n                        [ 0.3266,  0.2972],\n                        [-0.7053,  0.2924],\n                        [ 0.1768,  0.1795]],\n              \n                       [[-0.2671,  0.3598],\n                        [-0.5116, -0.1591],\n                        [-0.4300, -0.2598],\n                        [-0.5168, -0.8610],\n                        [ 0.0333, -0.0392]],\n              \n                       [[ 0.2338, -0.0235],\n                        [-0.2633,  0.1253],\n                        [-0.5069,  0.1514],\n                        [ 0.1677, -0.0415],\n                        [-0.4968, -0.5686]],\n              \n                       [[-0.1373,  0.1103],\n                        [-0.1461,  0.4142],\n                        [ 0.7837, -0.4532],\n                        [-0.4596,  0.4772],\n                        [ 0.3005,  0.1178]]]])),\n             ('W_cores.3',\n              tensor([[[[ 0.2891],\n                        [-0.4911]],\n              \n                       [[-0.2541],\n                        [-0.1819]]],\n              \n              \n                      [[[ 0.0952],\n                        [ 0.0310]],\n              \n                       [[ 0.1365],\n                        [-0.4213]]]]))])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TTLinear(hid, hid, [1, 2, 2, 2, 1], activation=None).state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:06:56.163920100Z",
     "start_time": "2023-11-17T09:06:56.140007300Z"
    }
   },
   "id": "cac08efd23230713"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:01:38.728736900Z",
     "start_time": "2023-11-17T09:01:38.723736200Z"
    }
   },
   "id": "d56ba61f54252e10"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 2, 2, 1])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TTLinear(hid, hid, [1, 2, 2, 2, 1], activation=None).state_dict()['W_cores.3'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:05:32.490803800Z",
     "start_time": "2023-11-17T09:05:32.475804200Z"
    }
   },
   "id": "42d5e5b41a34e25f"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('0.weight',\n              tensor([[ 4.5426e-01,  1.7516e-01],\n                      [-5.9689e-01,  1.6616e-01],\n                      [ 5.8600e-01, -4.6252e-01],\n                      [-4.5706e-01,  6.9215e-01],\n                      [ 5.6817e-01, -3.9449e-01],\n                      [ 4.2550e-01, -9.0462e-02],\n                      [-6.9716e-01,  5.3127e-02],\n                      [ 2.2846e-01, -2.1210e-01],\n                      [ 2.4599e-01, -6.0465e-01],\n                      [ 4.9004e-01,  6.0283e-01],\n                      [ 3.8995e-01,  1.1985e-01],\n                      [ 2.3288e-01, -5.1163e-01],\n                      [-1.7669e-01, -6.7506e-02],\n                      [-3.9350e-01, -5.2228e-01],\n                      [ 4.7561e-01,  4.7987e-01],\n                      [-6.4219e-01,  2.2501e-01],\n                      [ 2.8765e-01,  6.7173e-01],\n                      [ 4.0910e-01,  6.5007e-01],\n                      [-2.3150e-01,  4.9525e-01],\n                      [ 5.7516e-01, -6.6774e-01],\n                      [-5.6760e-01,  1.4312e-01],\n                      [ 3.8611e-01, -3.5130e-01],\n                      [ 7.7877e-02, -1.0265e-03],\n                      [ 1.7897e-01, -3.7996e-01],\n                      [ 3.9884e-01,  4.7023e-01],\n                      [-4.9063e-01,  6.8501e-03],\n                      [ 1.9619e-03,  2.2706e-01],\n                      [ 6.5873e-01,  2.0737e-01],\n                      [-1.6067e-01,  6.3508e-01],\n                      [-2.6908e-01, -2.0532e-01],\n                      [ 4.8278e-02, -5.3847e-01],\n                      [ 7.6945e-02, -4.7975e-01],\n                      [ 7.2705e-02,  6.7746e-02],\n                      [ 9.7878e-02, -5.9630e-01],\n                      [-6.7160e-01,  3.2535e-01],\n                      [ 6.0641e-01, -6.2747e-01],\n                      [ 2.6191e-01, -5.2052e-01],\n                      [ 4.4329e-02,  6.5786e-01],\n                      [ 5.3642e-01, -5.1699e-01],\n                      [ 4.3740e-01,  3.6933e-01],\n                      [-1.0846e-03,  6.8499e-01],\n                      [-2.8085e-01, -1.6455e-01],\n                      [-3.5738e-01,  1.0175e-01],\n                      [ 1.8723e-01,  5.6342e-02],\n                      [-3.9784e-01, -3.1832e-01],\n                      [ 2.4052e-01, -6.2001e-01],\n                      [-1.1012e-01, -1.5664e-02],\n                      [-2.8649e-01,  2.5733e-01],\n                      [ 4.5576e-02,  4.9643e-01],\n                      [-6.2799e-02, -4.4628e-01],\n                      [ 4.9961e-01,  9.8747e-02],\n                      [-2.0251e-01, -4.6606e-01],\n                      [ 1.6574e-01, -6.7440e-01],\n                      [ 1.8624e-01,  3.4963e-01],\n                      [-6.2027e-01, -4.6292e-01],\n                      [-5.0836e-01,  5.9433e-01],\n                      [ 6.0113e-01,  4.4266e-02],\n                      [ 6.6384e-01, -2.3639e-01],\n                      [-6.8647e-01,  2.4699e-01],\n                      [ 2.5051e-01,  6.9323e-01],\n                      [-2.0468e-04,  5.4192e-01],\n                      [ 4.3343e-01,  5.1178e-01],\n                      [-7.0168e-01,  5.8227e-01],\n                      [-6.0278e-01,  6.3393e-01],\n                      [-2.9303e-02, -6.2665e-01],\n                      [ 1.9664e-01, -1.4393e-01],\n                      [-6.3512e-01, -2.5635e-01],\n                      [ 7.2906e-02,  5.5073e-01],\n                      [-2.1739e-01,  4.2000e-01],\n                      [ 8.8550e-02,  2.3835e-02],\n                      [ 1.3530e-01, -4.6405e-01],\n                      [-5.8775e-01, -2.2218e-01],\n                      [-6.5892e-01, -3.2976e-01],\n                      [ 3.2531e-02, -4.6571e-01],\n                      [-2.9331e-01, -1.2706e-01],\n                      [-8.1461e-02, -3.9033e-01],\n                      [ 3.3977e-02, -9.9250e-02],\n                      [ 2.0223e-01,  3.1938e-02],\n                      [-3.5311e-01, -2.4345e-01],\n                      [-8.1499e-03, -4.4122e-01],\n                      [ 5.5356e-02, -4.9926e-02],\n                      [ 2.7434e-01,  1.6735e-01],\n                      [ 5.2919e-01, -2.3310e-02],\n                      [-5.2248e-01,  3.1608e-01],\n                      [-4.7789e-01, -9.7193e-02],\n                      [-2.2896e-01, -2.6831e-01],\n                      [-2.6162e-01,  6.4977e-01],\n                      [ 4.0479e-01,  1.9597e-01],\n                      [ 6.6394e-01, -6.4080e-01],\n                      [ 1.1410e-01,  4.5267e-01],\n                      [ 4.6972e-01, -5.6275e-01],\n                      [ 2.5165e-01, -4.0283e-01],\n                      [-2.7629e-02, -1.4755e-01],\n                      [-5.9041e-01, -6.7452e-01],\n                      [-4.6520e-01,  3.2086e-01],\n                      [ 3.2346e-01, -6.1502e-01],\n                      [-2.6555e-01,  1.1550e-02],\n                      [-6.1135e-01,  3.9842e-01],\n                      [ 6.4045e-01,  1.2506e-01],\n                      [-5.2539e-01,  1.6489e-01]], device='cuda:0')),\n             ('0.bias',\n              tensor([ 0.2567,  0.5599, -0.3762, -0.6335,  0.3107,  0.0440, -0.2304, -0.2963,\n                      -0.3646,  0.5724, -0.1220,  0.5100,  0.6312,  0.0896,  0.1506, -0.0482,\n                       0.4857, -0.6372,  0.2812, -0.1152,  0.3229, -0.0031, -0.2618, -0.0763,\n                       0.3818, -0.4911, -0.4470, -0.1584, -0.2565,  0.2778,  0.4759, -0.0757,\n                       0.6686, -0.2954, -0.3968, -0.3166, -0.4872, -0.4956, -0.6300, -0.6267,\n                       0.1846,  0.4312,  0.6639,  0.6023, -0.0407,  0.1372, -0.4231,  0.2733,\n                      -0.6780,  0.3335,  0.1297,  0.2173,  0.2589, -0.3246,  0.6068,  0.3375,\n                       0.4645,  0.0934,  0.4441,  0.4759,  0.3205,  0.5387, -0.1283,  0.4649,\n                       0.1629,  0.4255,  0.6887,  0.1601, -0.2625, -0.0704,  0.1991,  0.1192,\n                      -0.1932,  0.5540,  0.4248, -0.4392, -0.0576, -0.0679, -0.4432,  0.1031,\n                      -0.2171, -0.3651, -0.2274, -0.2521,  0.6764,  0.2712,  0.6959,  0.1939,\n                       0.1601,  0.2907,  0.1214, -0.5549, -0.4182, -0.1713,  0.0106,  0.2664,\n                       0.2723,  0.5610,  0.1439, -0.2413], device='cuda:0')),\n             ('2.b', tensor([1.], device='cuda:0')),\n             ('2.W_cores.0',\n              tensor([[[[ 0.1535, -0.6415],\n                        [-0.3165,  0.4345],\n                        [ 0.0849,  0.6621],\n                        [-0.6907,  0.2992],\n                        [ 0.6534,  0.7138]],\n              \n                       [[-0.3008,  0.5580],\n                        [ 0.0636,  0.0793],\n                        [-0.1224, -0.7488],\n                        [ 0.4623, -0.4777],\n                        [ 0.6029, -0.2764]],\n              \n                       [[-0.0957, -0.2153],\n                        [ 0.0635,  0.4273],\n                        [ 0.3982, -0.2369],\n                        [ 0.2415,  0.0296],\n                        [ 0.5417, -0.3618]],\n              \n                       [[ 0.3246, -0.9077],\n                        [-0.0994,  0.7248],\n                        [-0.6688,  0.4957],\n                        [ 0.5881, -0.5414],\n                        [-0.0112,  0.8398]],\n              \n                       [[-0.3988,  0.3778],\n                        [ 0.2347, -0.5582],\n                        [-0.5221, -0.2854],\n                        [-0.1552,  0.1822],\n                        [-0.0030,  0.1432]]]], device='cuda:0')),\n             ('2.W_cores.1',\n              tensor([[[[-0.2305,  0.5451],\n                        [ 0.2499, -0.4238]],\n              \n                       [[-0.6650,  0.3461],\n                        [-0.2202, -0.3975]]],\n              \n              \n                      [[[-0.6779, -0.7589],\n                        [ 0.3971, -0.3052]],\n              \n                       [[ 0.5634, -0.7190],\n                        [ 1.3661, -0.0890]]]], device='cuda:0')),\n             ('2.W_cores.2',\n              tensor([[[[-0.5024,  0.0710],\n                        [-0.2377,  0.2362],\n                        [ 0.6601,  0.0102],\n                        [ 0.1238,  0.0088],\n                        [-0.3312, -0.8713]],\n              \n                       [[-0.2216, -0.3059],\n                        [ 0.5006, -0.7572],\n                        [ 0.3080, -0.0441],\n                        [ 0.5860, -0.0314],\n                        [ 0.9045,  0.2648]],\n              \n                       [[ 0.0929, -0.0758],\n                        [-0.7615,  0.6183],\n                        [ 0.6552, -0.6347],\n                        [-0.2554,  0.0116],\n                        [-0.1085, -0.0396]],\n              \n                       [[-0.2291, -0.2013],\n                        [-0.6082, -0.5807],\n                        [-0.9185,  0.3713],\n                        [ 0.1874,  0.1046],\n                        [-0.0237,  0.0207]],\n              \n                       [[-0.8822, -0.3594],\n                        [-0.0649,  0.5702],\n                        [ 0.5408, -0.1120],\n                        [-0.5813, -0.2412],\n                        [-0.4031, -0.3704]]],\n              \n              \n                      [[[ 0.0691, -0.1779],\n                        [-0.3290,  0.7364],\n                        [ 0.3225, -0.0142],\n                        [-0.0077,  0.2525],\n                        [ 0.4124, -0.8165]],\n              \n                       [[ 0.1321, -0.3036],\n                        [ 0.7723, -0.1273],\n                        [-0.1674,  0.2843],\n                        [-0.3240,  0.5076],\n                        [ 0.7116,  0.1857]],\n              \n                       [[-0.4641, -0.2671],\n                        [-0.0229,  0.1645],\n                        [ 0.4269, -0.7682],\n                        [ 0.1886,  0.0274],\n                        [-0.2990, -0.1227]],\n              \n                       [[-0.4375, -0.5475],\n                        [-0.0757,  0.2378],\n                        [ 0.0502,  0.8636],\n                        [ 0.4439,  0.9248],\n                        [ 0.1012,  0.5206]],\n              \n                       [[-0.5493, -0.2888],\n                        [-0.0778,  0.1353],\n                        [ 0.3111, -0.0999],\n                        [ 0.3099,  0.6260],\n                        [ 0.0851,  0.4554]]]], device='cuda:0')),\n             ('2.W_cores.3',\n              tensor([[[[-0.5380],\n                        [ 0.3848]],\n              \n                       [[-0.1135],\n                        [ 0.4439]]],\n              \n              \n                      [[[-0.3382],\n                        [-0.0247]],\n              \n                       [[ 0.2149],\n                        [-0.8143]]]], device='cuda:0')),\n             ('4.b', tensor([1.], device='cuda:0')),\n             ('4.W_cores.0',\n              tensor([[[[ 0.7080, -0.6484],\n                        [-0.1300, -0.1797],\n                        [-0.3396,  0.4900],\n                        [-0.6994,  0.1930],\n                        [ 0.0175,  0.1071]],\n              \n                       [[ 0.0488, -0.2320],\n                        [ 0.3977, -0.4472],\n                        [-0.1488, -0.2186],\n                        [-0.2375, -0.0792],\n                        [-0.5365, -0.0731]],\n              \n                       [[ 0.2987,  0.0424],\n                        [ 0.4565, -0.4819],\n                        [-0.0743, -0.6682],\n                        [-0.1432, -0.3206],\n                        [-0.6549,  0.0350]],\n              \n                       [[-0.8208,  0.2450],\n                        [-0.3818, -0.3812],\n                        [-0.4471,  0.0893],\n                        [-0.3612, -0.3557],\n                        [-0.3557,  0.3954]],\n              \n                       [[-0.7036,  0.2831],\n                        [ 0.2163, -0.4349],\n                        [ 0.0294,  0.2577],\n                        [-0.6201, -0.3095],\n                        [-0.7016, -0.3993]]]], device='cuda:0')),\n             ('4.W_cores.1',\n              tensor([[[[ 0.3559,  0.1165],\n                        [ 0.2320,  0.1227]],\n              \n                       [[ 0.1110, -0.4758],\n                        [ 0.3661,  0.5303]]],\n              \n              \n                      [[[ 0.7771, -0.3327],\n                        [-0.5672, -0.7483]],\n              \n                       [[-0.0140, -0.2452],\n                        [ 0.1109, -0.6668]]]], device='cuda:0')),\n             ('4.W_cores.2',\n              tensor([[[[-0.0038,  0.0196],\n                        [ 0.0946,  0.9439],\n                        [ 0.9509, -0.2790],\n                        [ 0.7291,  0.6988],\n                        [-0.3686, -0.4142]],\n              \n                       [[ 0.0144,  0.1811],\n                        [ 0.8515, -0.4183],\n                        [ 0.3293,  0.6426],\n                        [ 0.2453,  0.1107],\n                        [-0.4782,  0.3573]],\n              \n                       [[ 0.0016, -0.7486],\n                        [ 0.1000, -0.0028],\n                        [-0.2277, -0.0527],\n                        [ 0.1802,  0.4378],\n                        [ 0.2956, -0.3165]],\n              \n                       [[-0.3601, -0.4091],\n                        [ 0.2798,  0.0761],\n                        [ 0.1296, -0.2609],\n                        [ 0.4809, -0.1170],\n                        [-0.1899, -0.4390]],\n              \n                       [[ 0.2118,  0.0680],\n                        [ 0.0863,  0.2978],\n                        [-0.1847, -0.3278],\n                        [ 0.0742, -0.3314],\n                        [-0.2753,  0.5118]]],\n              \n              \n                      [[[ 0.1627,  0.0711],\n                        [-0.2524, -0.2635],\n                        [-0.0887,  0.2511],\n                        [ 0.6131, -0.0300],\n                        [-0.1085, -0.2740]],\n              \n                       [[-0.0449,  0.4264],\n                        [-0.0916,  0.3671],\n                        [-0.3331, -0.4351],\n                        [-0.4187,  0.0915],\n                        [-0.6131,  0.3868]],\n              \n                       [[-0.1318, -0.0222],\n                        [ 0.1270,  0.0501],\n                        [-0.0775, -0.0408],\n                        [-0.2745,  0.8736],\n                        [ 0.2795, -0.6151]],\n              \n                       [[ 0.4696, -0.3927],\n                        [-0.4510,  0.1642],\n                        [-0.5636, -0.3913],\n                        [-1.0493,  0.3094],\n                        [-0.8458, -0.2615]],\n              \n                       [[-0.3444,  0.0102],\n                        [ 0.9050,  0.4367],\n                        [-0.0545,  0.0934],\n                        [-0.5569,  0.9666],\n                        [ 0.3577,  0.1975]]]], device='cuda:0')),\n             ('4.W_cores.3',\n              tensor([[[[ 0.0460],\n                        [ 0.3800]],\n              \n                       [[-0.2849],\n                        [-0.3353]]],\n              \n              \n                      [[[-0.5041],\n                        [ 0.1345]],\n              \n                       [[ 0.1649],\n                        [-0.1691]]]], device='cuda:0')),\n             ('6.weight',\n              tensor([[-0.0473, -0.0698,  0.0376, -0.0903,  0.0892, -0.0472,  0.0483, -0.0795,\n                       -0.0677,  0.0110,  0.0355,  0.0775,  0.0836, -0.0058, -0.0129,  0.0165,\n                       -0.0232,  0.0034, -0.0947, -0.0821,  0.0685, -0.0584,  0.0787,  0.0110,\n                        0.0244,  0.0909, -0.0556, -0.0158,  0.0177,  0.0342, -0.0973,  0.0355,\n                       -0.0590,  0.0131,  0.0677, -0.0100, -0.0032, -0.0075,  0.0834,  0.0568,\n                        0.0168, -0.0602, -0.0543,  0.0797,  0.0719,  0.0579, -0.0780,  0.0779,\n                       -0.0096,  0.0737,  0.0869,  0.0110, -0.0416,  0.0941, -0.0521,  0.0653,\n                       -0.0959, -0.0315, -0.0872, -0.0449,  0.0425, -0.0717, -0.0865,  0.0715,\n                        0.0534, -0.0011, -0.0705, -0.0265, -0.0324,  0.0618, -0.0327, -0.0288,\n                       -0.0709, -0.0471,  0.0541,  0.0644,  0.0145, -0.0375,  0.0960,  0.0197,\n                       -0.0386, -0.0347, -0.0140,  0.0474,  0.0366,  0.0725, -0.0045,  0.0827,\n                       -0.0406, -0.0461, -0.0369, -0.0938, -0.0656, -0.0905, -0.0059,  0.0009,\n                       -0.0260, -0.0683,  0.0907, -0.0331]], device='cuda:0')),\n             ('6.bias', tensor([0.0477], device='cuda:0'))])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:15:46.940032100Z",
     "start_time": "2023-11-17T08:15:46.856032200Z"
    }
   },
   "id": "2105e09bd4b31d97"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "x_grid = np.linspace(0, 1, 51)\n",
    "t_grid = np.linspace(0, 1, 51)\n",
    "\n",
    "x = torch.from_numpy(x_grid)\n",
    "t = torch.from_numpy(t_grid)\n",
    "\n",
    "grid = torch.cartesian_prod(x, t).float().to(device)\n",
    "\n",
    "def nn_autograd_simple(model, points, order,axis=0):\n",
    "    points.requires_grad=True\n",
    "    f = model(points).sum()\n",
    "    for i in range(order):\n",
    "        grads, = torch.autograd.grad(f, points, create_graph=True)\n",
    "        f = grads[:,axis].sum()\n",
    "    return grads[:,axis]\n",
    "\n",
    "func_bnd1 = lambda x: 10 ** 4 * torch.sin((1 / 10) * x * (x - 1)) ** 2\n",
    "bnd1 = torch.cartesian_prod(x, torch.from_numpy(np.array([0], dtype=np.float64))).float().to(device)\n",
    "bndval1 = func_bnd1(bnd1[:, 0])\n",
    "\n",
    "# du/dx (x,0) = 1e3*sin^2(x(x-1)/10)\n",
    "func_bnd2 = lambda x: 10 ** 3 * torch.sin((1 / 10) * x * (x - 1)) ** 2\n",
    "bnd2 = torch.cartesian_prod(x, torch.from_numpy(np.array([0], dtype=np.float64))).float().to(device)\n",
    "bop2 = {\n",
    "    'du/dt':\n",
    "        {\n",
    "            'coeff': 1,\n",
    "            'du/dt': [1],\n",
    "            'pow': 1,\n",
    "            'var': 0\n",
    "        }\n",
    "}\n",
    "bndval2 = func_bnd2(bnd2[:, 0])\n",
    "\n",
    "# u(0,t) = u(1,t)\n",
    "bnd3_left = torch.cartesian_prod(torch.from_numpy(np.array([0], dtype=np.float64)), t).float().to(device)\n",
    "bnd3_right = torch.cartesian_prod(torch.from_numpy(np.array([1], dtype=np.float64)), t).float().to(device)\n",
    "bnd3 = [bnd3_left, bnd3_right]\n",
    "\n",
    "# du/dt(0,t) = du/dt(1,t)\n",
    "bnd4_left = torch.cartesian_prod(torch.from_numpy(np.array([0], dtype=np.float64)), t).float().to(device)\n",
    "bnd4_right = torch.cartesian_prod(torch.from_numpy(np.array([1], dtype=np.float64)), t).float().to(device)\n",
    "bnd4 = [bnd4_left, bnd4_right]\n",
    "\n",
    "bop4 = {\n",
    "    'du/dx':\n",
    "        {\n",
    "            'coeff': 1,\n",
    "            'du/dx': [0],\n",
    "            'pow': 1,\n",
    "            'var': 0\n",
    "        }\n",
    "}\n",
    "bcond_type = 'periodic'\n",
    "\n",
    "bconds = [[bnd1, bndval1, 'dirichlet'],\n",
    "          [bnd2, bop2, bndval2, 'operator'],\n",
    "          [bnd3, bcond_type],\n",
    "          [bnd4, bop4, bcond_type]]\n",
    "\n",
    "def wave_op(model, grid):\n",
    "    u_xx = nn_autograd_simple(model, grid, order=2, axis=0)\n",
    "    u_tt = nn_autograd_simple(model, grid, order=2, axis=1)\n",
    "    a = -(1 / 4)\n",
    "\n",
    "    op = u_tt + a * u_xx\n",
    "\n",
    "    return op\n",
    "\n",
    "def op_loss(operator):\n",
    "    return torch.mean(torch.square(operator))\n",
    "\n",
    "def bcs_loss(model):\n",
    "    bc1 = model(bnd1)\n",
    "    bc2 = nn_autograd_simple(model, bnd2, order=1, axis=1)\n",
    "    bc3 = model(bnd3_left) - model(bnd3_right)\n",
    "    bc4 = nn_autograd_simple(model, bnd4_left, order=1, axis=0) - nn_autograd_simple(model, bnd4_right, order=1, axis=0)\n",
    "    \n",
    "    loss_bc1 = torch.mean(torch.square(bc1.reshape(-1) - bndval1))\n",
    "    loss_bc2 = torch.mean(torch.square(bc2.reshape(-1) - bndval2))\n",
    "    loss_bc3 = torch.mean(torch.square(bc3))\n",
    "    loss_bc4 = torch.mean(torch.square(bc4))\n",
    "    \n",
    "    loss = loss_bc1 + loss_bc2 + loss_bc3 + loss_bc4\n",
    "    return loss\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:13:09.228026900Z",
     "start_time": "2023-11-17T08:13:09.211017300Z"
    }
   },
   "id": "49eb9fa1b1758bd3"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def draw_fig(model, grid):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    xs = grid[:, 0].detach().cpu().numpy().reshape(-1)\n",
    "    ys = grid[:, 1].detach().cpu().numpy().reshape(-1)\n",
    "    zs = model(grid).detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "    ax.plot_trisurf(xs, ys, zs, cmap=cm.jet, linewidth=0.2, alpha=1)\n",
    "\n",
    "    ax.set_title(\"wave periodic\")\n",
    "    ax.set_xlabel(\"$x$\")\n",
    "    ax.set_ylabel(\"$t$\")\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:13:10.189087700Z",
     "start_time": "2023-11-17T08:13:10.170927Z"
    }
   },
   "id": "b80489d9b2b344fa"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def loss_fn(model):\n",
    "    # model.load_state_dict(params)\n",
    "    operator = wave_op(model, grid)\n",
    "    loss = op_loss(operator) + 1000 * bcs_loss(model)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:13:10.381197900Z",
     "start_time": "2023-11-17T08:13:10.373199300Z"
    }
   },
   "id": "fb162c9cc7330416"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:12:59.453936400Z",
     "start_time": "2023-11-17T08:12:59.439789200Z"
    }
   },
   "id": "993436592d25496e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 15969.0361328125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m     param\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m new_param\n\u001B[0;32m     12\u001B[0m operator \u001B[38;5;241m=\u001B[39m wave_op(model, grid)\n\u001B[1;32m---> 13\u001B[0m loss \u001B[38;5;241m=\u001B[39m op_loss(operator) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1000\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[43mbcs_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m loss \u001B[38;5;241m<\u001B[39m best_loss:\n\u001B[0;32m     16\u001B[0m     best_loss \u001B[38;5;241m=\u001B[39m loss\n",
      "Cell \u001B[1;32mIn[4], line 77\u001B[0m, in \u001B[0;36mbcs_loss\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m     75\u001B[0m bc2 \u001B[38;5;241m=\u001B[39m nn_autograd_simple(model, bnd2, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     76\u001B[0m bc3 \u001B[38;5;241m=\u001B[39m model(bnd3_left) \u001B[38;5;241m-\u001B[39m model(bnd3_right)\n\u001B[1;32m---> 77\u001B[0m bc4 \u001B[38;5;241m=\u001B[39m \u001B[43mnn_autograd_simple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbnd4_left\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m nn_autograd_simple(model, bnd4_right, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     79\u001B[0m loss_bc1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(torch\u001B[38;5;241m.\u001B[39msquare(bc1\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m-\u001B[39m bndval1))\n\u001B[0;32m     80\u001B[0m loss_bc2 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(torch\u001B[38;5;241m.\u001B[39msquare(bc2\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m-\u001B[39m bndval2))\n",
      "Cell \u001B[1;32mIn[4], line 14\u001B[0m, in \u001B[0;36mnn_autograd_simple\u001B[1;34m(model, points, order, axis)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(order):\n\u001B[0;32m     13\u001B[0m     grads, \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mgrad(f, points, create_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 14\u001B[0m     f \u001B[38;5;241m=\u001B[39m \u001B[43mgrads\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m grads[:,axis]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_iterations = 20000 \n",
    "learning_rate = 0.01  \n",
    "best_loss = float(\"inf\") \n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    current_params = [param.clone() for param in model.parameters()]\n",
    "    new_params = [param + torch.randn_like(param) * learning_rate for param in current_params]\n",
    "\n",
    "    for param, new_param in zip(model.parameters(), new_params):\n",
    "        param.data = new_param\n",
    "        \n",
    "    operator = wave_op(model, grid)\n",
    "    loss = op_loss(operator) + 1000 * bcs_loss(model)\n",
    "  \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "    else:\n",
    "        for param, current_param in zip(model.parameters(), current_params):\n",
    "            param.data = current_param\n",
    "\n",
    "    if iteration % 500 == 0:\n",
    "        print(f\"Iteration {iteration}: Loss = {best_loss}\")\n",
    "\n",
    "print(\"Optimization complete. Best loss:\", best_loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:13:01.905565900Z",
     "start_time": "2023-11-17T08:12:59.456894200Z"
    }
   },
   "id": "f10ae034b1763c05"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T10:45:55.858395400Z",
     "start_time": "2023-11-17T10:45:55.846889900Z"
    }
   },
   "id": "7a8f518e67967fec"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Linear(in_features=2, out_features=100, bias=True)\n  (1): Tanh()\n  (2): TTLinear(\n    (TTLayer): inp_modes=[5, 2, 5, 2], out_modes=[5, 2, 5, 2], mat_ranks=[1, 2, 2, 2, 1]\n    (W_cores): ParameterList(\n        (0): Parameter containing: [torch.float32 of size 1x5x5x2 (GPU 0)]\n        (1): Parameter containing: [torch.float32 of size 2x2x2x2 (GPU 0)]\n        (2): Parameter containing: [torch.float32 of size 2x5x5x2 (GPU 0)]\n        (3): Parameter containing: [torch.float32 of size 2x2x2x1 (GPU 0)]\n    )\n  )\n  (3): Tanh()\n  (4): TTLinear(\n    (TTLayer): inp_modes=[5, 2, 5, 2], out_modes=[5, 2, 5, 2], mat_ranks=[1, 2, 2, 2, 1]\n    (W_cores): ParameterList(\n        (0): Parameter containing: [torch.float32 of size 1x5x5x2 (GPU 0)]\n        (1): Parameter containing: [torch.float32 of size 2x2x2x2 (GPU 0)]\n        (2): Parameter containing: [torch.float32 of size 2x5x5x2 (GPU 0)]\n        (3): Parameter containing: [torch.float32 of size 2x2x2x1 (GPU 0)]\n    )\n  )\n  (5): Tanh()\n  (6): Linear(in_features=100, out_features=1, bias=True)\n)"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T10:50:12.634612200Z",
     "start_time": "2023-11-17T10:50:12.622596800Z"
    }
   },
   "id": "d43d265e14bc4ec6"
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "mu = 0.01\n",
    "\n",
    "current_params = [param.clone() for param in model.parameters()]\n",
    "\n",
    "xi = [torch.randn_like(param) for param in current_params]\n",
    "new_params = [x + y for x, y in zip(current_params, list(map(lambda x: mu * x, xi)))]\n",
    "\n",
    "# Создайте новую версию параметров модели с небольшими случайными изменениями\n",
    "model_temp = deepcopy(model)\n",
    "\n",
    "# Установите параметры модели на новые значения\n",
    "for param, new_param in zip(model_temp.parameters(), new_params):\n",
    "    param.data = new_param\n",
    "\n",
    "# Рассчитайте функцию потерь на новых параметрах\n",
    "loss_curr = loss_fn(model)\n",
    "loss_temp = loss_fn(model_temp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:18:39.382083100Z",
     "start_time": "2023-11-17T11:18:39.307009800Z"
    }
   },
   "id": "f2ee256af65c529e"
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "delta_losses = list(map(lambda x: (loss_temp - loss_curr) * x, xi))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:18:39.570015Z",
     "start_time": "2023-11-17T11:18:39.555342800Z"
    }
   },
   "id": "d95a7155421cf78b"
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "N_dot_mu = [mu * len(item.flatten()) for item in xi]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:18:39.961402700Z",
     "start_time": "2023-11-17T11:18:39.934880200Z"
    }
   },
   "id": "6aad25a96a743d91"
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "grads = [x / y for x, y in zip(delta_losses, N_dot_mu)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:18:40.322103100Z",
     "start_time": "2023-11-17T11:18:40.316099500Z"
    }
   },
   "id": "e2dfea91002d36ef"
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[0., 0.],\n         [0., -0.],\n         [-0., -0.],\n         [0., 0.],\n         [-0., -0.],\n         [-0., 0.],\n         [-0., -0.],\n         [0., -0.],\n         [-0., 0.],\n         [-0., -0.],\n         [-0., -0.],\n         [-0., 0.],\n         [0., -0.],\n         [-0., 0.],\n         [-0., 0.],\n         [-0., 0.],\n         [0., -0.],\n         [0., -0.],\n         [-0., -0.],\n         [0., -0.],\n         [-0., 0.],\n         [-0., -0.],\n         [0., 0.],\n         [-0., 0.],\n         [-0., -0.],\n         [0., -0.],\n         [0., 0.],\n         [0., -0.],\n         [-0., -0.],\n         [-0., -0.],\n         [-0., -0.],\n         [0., -0.],\n         [0., 0.],\n         [0., -0.],\n         [0., -0.],\n         [-0., -0.],\n         [-0., 0.],\n         [0., 0.],\n         [0., -0.],\n         [0., 0.],\n         [-0., 0.],\n         [0., -0.],\n         [-0., 0.],\n         [-0., 0.],\n         [0., 0.],\n         [0., 0.],\n         [-0., -0.],\n         [0., 0.],\n         [-0., -0.],\n         [0., 0.],\n         [-0., 0.],\n         [0., 0.],\n         [0., 0.],\n         [0., -0.],\n         [-0., -0.],\n         [-0., -0.],\n         [-0., 0.],\n         [-0., -0.],\n         [0., 0.],\n         [-0., 0.],\n         [0., 0.],\n         [-0., -0.],\n         [0., 0.],\n         [0., 0.],\n         [0., 0.],\n         [-0., 0.],\n         [-0., -0.],\n         [-0., 0.],\n         [-0., -0.],\n         [-0., -0.],\n         [-0., 0.],\n         [0., 0.],\n         [0., -0.],\n         [-0., -0.],\n         [-0., -0.],\n         [0., 0.],\n         [-0., 0.],\n         [0., 0.],\n         [0., 0.],\n         [-0., -0.],\n         [-0., -0.],\n         [0., 0.],\n         [-0., -0.],\n         [0., -0.],\n         [-0., 0.],\n         [0., -0.],\n         [-0., -0.],\n         [0., -0.],\n         [0., -0.],\n         [0., -0.],\n         [0., 0.],\n         [0., 0.],\n         [-0., 0.],\n         [0., -0.],\n         [-0., 0.],\n         [-0., -0.],\n         [-0., -0.],\n         [0., 0.],\n         [-0., 0.],\n         [-0., 0.]], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([0., 0., 0., 0., -0., -0., -0., 0., -0., -0., -0., 0., -0., -0., -0., -0., 0., 0., 0., 0., -0., -0., 0., 0.,\n         -0., 0., 0., 0., 0., 0., -0., -0., -0., 0., -0., 0., -0., -0., 0., -0., 0., 0., -0., -0., 0., -0., -0., -0.,\n         -0., 0., 0., -0., -0., -0., -0., -0., -0., 0., -0., 0., -0., -0., -0., 0., 0., -0., 0., 0., -0., 0., -0., -0.,\n         0., 0., -0., 0., 0., -0., 0., -0., 0., -0., -0., 0., -0., 0., 0., -0., -0., 0., -0., -0., 0., 0., 0., -0.,\n         0., 0., 0., 0.], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([-0.], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([[[[-0., -0.],\n           [-0., -0.],\n           [-0., -0.],\n           [0., 0.],\n           [-0., -0.]],\n \n          [[-0., -0.],\n           [0., -0.],\n           [0., 0.],\n           [0., 0.],\n           [-0., -0.]],\n \n          [[-0., 0.],\n           [-0., -0.],\n           [-0., 0.],\n           [0., 0.],\n           [-0., 0.]],\n \n          [[-0., -0.],\n           [-0., 0.],\n           [-0., -0.],\n           [-0., -0.],\n           [-0., 0.]],\n \n          [[-0., 0.],\n           [-0., -0.],\n           [0., 0.],\n           [0., 0.],\n           [-0., 0.]]]], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([[[[0., -0.],\n           [0., 0.]],\n \n          [[0., 0.],\n           [0., 0.]]],\n \n \n         [[[-0., -0.],\n           [-0., 0.]],\n \n          [[-0., -0.],\n           [0., 0.]]]], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([[[[-0., -0.],\n           [-0., 0.],\n           [-0., 0.],\n           [-0., -0.],\n           [0., 0.]],\n \n          [[-0., 0.],\n           [-0., 0.],\n           [0., -0.],\n           [0., -0.],\n           [0., -0.]],\n \n          [[-0., 0.],\n           [0., -0.],\n           [0., -0.],\n           [-0., -0.],\n           [0., 0.]],\n \n          [[0., -0.],\n           [0., -0.],\n           [0., -0.],\n           [0., 0.],\n           [-0., -0.]],\n \n          [[-0., 0.],\n           [-0., 0.],\n           [-0., 0.],\n           [0., -0.],\n           [0., 0.]]],\n \n \n         [[[-0., -0.],\n           [0., -0.],\n           [-0., 0.],\n           [-0., 0.],\n           [0., -0.]],\n \n          [[-0., 0.],\n           [-0., -0.],\n           [0., 0.],\n           [-0., 0.],\n           [0., -0.]],\n \n          [[-0., -0.],\n           [-0., -0.],\n           [0., -0.],\n           [0., 0.],\n           [-0., -0.]],\n \n          [[0., 0.],\n           [0., -0.],\n           [0., 0.],\n           [-0., -0.],\n           [0., -0.]],\n \n          [[-0., -0.],\n           [0., -0.],\n           [-0., 0.],\n           [-0., 0.],\n           [-0., 0.]]]], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([[[[-0.],\n           [-0.]],\n \n          [[0.],\n           [0.]]],\n \n \n         [[[-0.],\n           [-0.]],\n \n          [[0.],\n           [0.]]]], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([0.], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([[[[0., 0.],\n           [0., 0.],\n           [-0., -0.],\n           [0., 0.],\n           [0., -0.]],\n \n          [[0., -0.],\n           [-0., 0.],\n           [0., -0.],\n           [-0., -0.],\n           [0., -0.]],\n \n          [[0., -0.],\n           [-0., 0.],\n           [-0., 0.],\n           [-0., 0.],\n           [-0., -0.]],\n \n          [[0., -0.],\n           [0., -0.],\n           [0., 0.],\n           [0., 0.],\n           [-0., 0.]],\n \n          [[-0., 0.],\n           [0., 0.],\n           [0., -0.],\n           [0., -0.],\n           [0., -0.]]]], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([[[[-0., 0.],\n           [-0., -0.]],\n \n          [[-0., 0.],\n           [0., -0.]]],\n \n \n         [[[0., -0.],\n           [-0., -0.]],\n \n          [[0., -0.],\n           [-0., -0.]]]], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([[[[0., 0.],\n           [0., -0.],\n           [-0., 0.],\n           [-0., 0.],\n           [0., -0.]],\n \n          [[-0., -0.],\n           [-0., -0.],\n           [0., 0.],\n           [0., -0.],\n           [0., -0.]],\n \n          [[-0., 0.],\n           [0., 0.],\n           [0., -0.],\n           [0., 0.],\n           [-0., 0.]],\n \n          [[-0., -0.],\n           [0., 0.],\n           [-0., 0.],\n           [-0., 0.],\n           [0., 0.]],\n \n          [[0., -0.],\n           [0., -0.],\n           [-0., 0.],\n           [-0., -0.],\n           [0., -0.]]],\n \n \n         [[[0., -0.],\n           [0., 0.],\n           [0., -0.],\n           [-0., 0.],\n           [0., 0.]],\n \n          [[0., -0.],\n           [0., 0.],\n           [0., -0.],\n           [-0., -0.],\n           [-0., 0.]],\n \n          [[-0., -0.],\n           [0., -0.],\n           [0., 0.],\n           [0., 0.],\n           [-0., 0.]],\n \n          [[-0., -0.],\n           [-0., 0.],\n           [0., -0.],\n           [-0., -0.],\n           [0., 0.]],\n \n          [[0., -0.],\n           [-0., 0.],\n           [-0., -0.],\n           [-0., 0.],\n           [-0., -0.]]]], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([[[[-0.],\n           [-0.]],\n \n          [[-0.],\n           [-0.]]],\n \n \n         [[[0.],\n           [-0.]],\n \n          [[-0.],\n           [0.]]]], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([[0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., -0., 0., 0., 0., 0., 0., -0., -0., 0., 0., -0., 0., -0.,\n          0., -0., 0., -0., 0., -0., 0., 0., 0., 0., -0., -0., 0., 0., -0., 0., -0., 0., 0., -0., -0., -0., -0., 0.,\n          0., 0., -0., 0., 0., -0., 0., 0., 0., -0., -0., -0., 0., -0., 0., -0., -0., 0., -0., 0., -0., -0., 0., 0.,\n          -0., 0., -0., -0., -0., -0., 0., 0., -0., 0., -0., 0., -0., 0., 0., -0., -0., -0., 0., -0., 0., 0., 0., 0.,\n          0., -0., 0., -0.]], device='cuda:0', grad_fn=<DivBackward0>),\n tensor([-0.], device='cuda:0', grad_fn=<DivBackward0>)]"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:18:40.990988400Z",
     "start_time": "2023-11-17T11:18:40.947423600Z"
    }
   },
   "id": "189e6ace67198970"
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "grads_dot_lr = [learning_rate * g for g in grads]\n",
    "params = [param - grad for param, grad in zip(current_params, grads_dot_lr)] "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:18:41.840139600Z",
     "start_time": "2023-11-17T11:18:41.825962100Z"
    }
   },
   "id": "6fa80784c5161942"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "for param, new_param in zip(model.parameters(), params):\n",
    "        param.data = new_param"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:08:47.400720100Z",
     "start_time": "2023-11-17T11:08:47.380698200Z"
    }
   },
   "id": "7cc1290cb3606cf7"
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(9697772., device='cuda:0', grad_fn=<AddBackward0>)"
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:08:59.489069200Z",
     "start_time": "2023-11-17T11:08:59.419895300Z"
    }
   },
   "id": "ef917ad379c4b5f5"
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 1.119643794470657e+24\n",
      "Iteration 10: Loss = 1.119643794470657e+24\n",
      "Iteration 20: Loss = 1.119643794470657e+24\n",
      "Iteration 30: Loss = 1.119643794470657e+24\n",
      "Iteration 40: Loss = 1.119643794470657e+24\n",
      "Iteration 50: Loss = 1.119643794470657e+24\n",
      "Iteration 60: Loss = 1.119643794470657e+24\n",
      "Iteration 70: Loss = 1.119643794470657e+24\n",
      "Iteration 80: Loss = 1.119643794470657e+24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[180], line 34\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param, new_param \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(model\u001B[38;5;241m.\u001B[39mparameters(), params):\n\u001B[0;32m     32\u001B[0m     param\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m new_param\n\u001B[1;32m---> 34\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m loss \u001B[38;5;241m<\u001B[39m best_loss:\n\u001B[0;32m     36\u001B[0m     best_loss \u001B[38;5;241m=\u001B[39m loss    \n",
      "Cell \u001B[1;32mIn[12], line 3\u001B[0m, in \u001B[0;36mloss_fn\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mloss_fn\u001B[39m(model):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# model.load_state_dict(params)\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m     operator \u001B[38;5;241m=\u001B[39m \u001B[43mwave_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     loss \u001B[38;5;241m=\u001B[39m op_loss(operator) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1000\u001B[39m \u001B[38;5;241m*\u001B[39m bcs_loss(model)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "Cell \u001B[1;32mIn[10], line 63\u001B[0m, in \u001B[0;36mwave_op\u001B[1;34m(model, grid)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwave_op\u001B[39m(model, grid):\n\u001B[0;32m     62\u001B[0m     u_xx \u001B[38;5;241m=\u001B[39m nn_autograd_simple(model, grid, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 63\u001B[0m     u_tt \u001B[38;5;241m=\u001B[39m \u001B[43mnn_autograd_simple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     64\u001B[0m     a \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m     66\u001B[0m     op \u001B[38;5;241m=\u001B[39m u_tt \u001B[38;5;241m+\u001B[39m a \u001B[38;5;241m*\u001B[39m u_xx\n",
      "Cell \u001B[1;32mIn[10], line 13\u001B[0m, in \u001B[0;36mnn_autograd_simple\u001B[1;34m(model, points, order, axis)\u001B[0m\n\u001B[0;32m     11\u001B[0m f \u001B[38;5;241m=\u001B[39m model(points)\u001B[38;5;241m.\u001B[39msum()\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(order):\n\u001B[1;32m---> 13\u001B[0m     grads, \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpoints\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m     f \u001B[38;5;241m=\u001B[39m grads[:,axis]\u001B[38;5;241m.\u001B[39msum()\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m grads[:,axis]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\torch\\autograd\\__init__.py:303\u001B[0m, in \u001B[0;36mgrad\u001B[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001B[0m\n\u001B[0;32m    301\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _vmap_internals\u001B[38;5;241m.\u001B[39m_vmap(vjp, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, allow_none_pass_through\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)(grad_outputs_)\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 303\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_outputs_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    305\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_unused\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "num_iterations = 1000 \n",
    "learning_rate = 0.01  \n",
    "best_loss = float(\"inf\")  \n",
    "for iteration in range(num_iterations):\n",
    "    \n",
    "    # Текущие параметры в список\n",
    "    current_params = [param.clone() for param in model.parameters()] \n",
    "    # Расчет кси\n",
    "    xi = [torch.randn_like(param) for param in current_params]\n",
    "    # Расчет новых параметров: theta + mu * xi\n",
    "    new_params = [x + y for x, y in zip(current_params, list(map(lambda x: mu * x, xi)))]\n",
    "    \n",
    "    model_temp = deepcopy(model)\n",
    "    # применяю новые параметры к модели\n",
    "    for param, new_param in zip(model_temp.parameters(), new_params):\n",
    "        param.data = new_param\n",
    "    # считаем лосс от текущей модели и новой\n",
    "    loss_curr = loss_fn(model)\n",
    "    loss_temp = loss_fn(model_temp)\n",
    "    \n",
    "    delta_losses = list(map(lambda x: (loss_temp - loss_curr) * x, xi))\n",
    "    \n",
    "    # считаем произведение mu * N\n",
    "    N_dot_mu = [mu * len(item.flatten()) for item in xi]\n",
    "    # считаем  mu * N\n",
    "    grads = [x / y for x, y in zip(delta_losses, N_dot_mu)]\n",
    "    \n",
    "    grads_dot_lr = [learning_rate * g for g in grads]\n",
    "    params = [param - grad for param, grad in zip(current_params, grads_dot_lr)] \n",
    "    \n",
    "    for param, new_param in zip(model.parameters(), params):\n",
    "        param.data = new_param\n",
    "        \n",
    "    loss = loss_fn(model)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss    \n",
    "    if iteration % 10 == 0:\n",
    "        print(f\"Iteration {iteration}: Loss = {best_loss}\")\n",
    "\n",
    "print(\"Optimization complete. Best loss:\", best_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:21:50.372086100Z",
     "start_time": "2023-11-17T11:21:44.729015400Z"
    }
   },
   "id": "9d29eb819a4002f0"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ac57009d4974c0af"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "minimizer_args = dict(method='L-BFGS-B', options={'disp':True, 'maxiter':5000}, jac = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:13:21.025298900Z",
     "start_time": "2023-11-17T08:13:21.004299100Z"
    }
   },
   "id": "b4f37bfafa930df2"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimizer_args['jac']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:13:21.380268200Z",
     "start_time": "2023-11-17T08:13:21.374269Z"
    }
   },
   "id": "ad7fefdfe1a8e103"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "optimizer = MinimizeWrapper(model.parameters(), minimizer_args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:13:22.120246Z",
     "start_time": "2023-11-17T08:13:22.108246Z"
    }
   },
   "id": "a68eb985c03e1cef"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss\n\u001B[1;32m----> 6\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    276\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    277\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    278\u001B[0m                                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 280\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    283\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\pytorch_minimize\\optim.py:163\u001B[0m, in \u001B[0;36mMinimizeWrapper.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;66;03m# run the minimizer\u001B[39;00m\n\u001B[0;32m    162\u001B[0m x0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mravel_pack(params)\n\u001B[1;32m--> 163\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mres \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mminimize(torch_wrapper, x0, hess\u001B[38;5;241m=\u001B[39mhess, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mminimizer_args)\n\u001B[0;32m    165\u001B[0m \u001B[38;5;66;03m# set the final parameters\u001B[39;00m\n\u001B[0;32m    166\u001B[0m _params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnp_unravel_unpack(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mres\u001B[38;5;241m.\u001B[39mx)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\pytorch_minimize\\optim.py:116\u001B[0m, in \u001B[0;36mMinimizeWrapper.minimize\u001B[1;34m(self, func, x0, **minimizer_args)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mminimize\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, x0, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mminimizer_args):\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m minimize(func, x0, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mminimizer_args)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\scipy\\optimize\\_minimize.py:710\u001B[0m, in \u001B[0;36mminimize\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[0;32m    707\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[0;32m    708\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    709\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml-bfgs-b\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 710\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001B[0;32m    711\u001B[0m                            callback\u001B[38;5;241m=\u001B[39mcallback, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    712\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtnc\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    713\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[0;32m    714\u001B[0m                         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:307\u001B[0m, in \u001B[0;36m_minimize_lbfgsb\u001B[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    305\u001B[0m         iprint \u001B[38;5;241m=\u001B[39m disp\n\u001B[1;32m--> 307\u001B[0m sf \u001B[38;5;241m=\u001B[39m \u001B[43m_prepare_scalar_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnew_bounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    309\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mfinite_diff_rel_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfinite_diff_rel_step\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    311\u001B[0m func_and_grad \u001B[38;5;241m=\u001B[39m sf\u001B[38;5;241m.\u001B[39mfun_and_grad\n\u001B[0;32m    313\u001B[0m fortran_int \u001B[38;5;241m=\u001B[39m _lbfgsb\u001B[38;5;241m.\u001B[39mtypes\u001B[38;5;241m.\u001B[39mintvar\u001B[38;5;241m.\u001B[39mdtype\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\scipy\\optimize\\_optimize.py:383\u001B[0m, in \u001B[0;36m_prepare_scalar_function\u001B[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001B[0m\n\u001B[0;32m    379\u001B[0m     bounds \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m-\u001B[39mnp\u001B[38;5;241m.\u001B[39minf, np\u001B[38;5;241m.\u001B[39minf)\n\u001B[0;32m    381\u001B[0m \u001B[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001B[39;00m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;66;03m# calculation reduces overall function evaluations.\u001B[39;00m\n\u001B[1;32m--> 383\u001B[0m sf \u001B[38;5;241m=\u001B[39m \u001B[43mScalarFunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    384\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mfinite_diff_rel_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepsilon\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sf\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:158\u001B[0m, in \u001B[0;36mScalarFunction.__init__\u001B[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001B[0m\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m fun_wrapped(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_fun_impl \u001B[38;5;241m=\u001B[39m update_fun\n\u001B[1;32m--> 158\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;66;03m# Gradient evaluation\u001B[39;00m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(grad):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001B[0m, in \u001B[0;36mScalarFunction._update_fun\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_fun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    250\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated:\n\u001B[1;32m--> 251\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.update_fun\u001B[1;34m()\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_fun\u001B[39m():\n\u001B[1;32m--> 155\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[43mfun_wrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnfev \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m fx \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(fx):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\scipy\\optimize\\_optimize.py:77\u001B[0m, in \u001B[0;36mMemoizeJac.__call__\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m     76\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" returns the function value \"\"\"\u001B[39;00m\n\u001B[1;32m---> 77\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\scipy\\optimize\\_optimize.py:71\u001B[0m, in \u001B[0;36mMemoizeJac._compute_if_needed\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(x \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m---> 71\u001B[0m     fg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     73\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\pytorch_minimize\\optim.py:132\u001B[0m, in \u001B[0;36mMinimizeWrapper.step.<locals>.torch_wrapper\u001B[1;34m(x, return_grad, *args)\u001B[0m\n\u001B[0;32m    130\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfloatX(loss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_grad:\n\u001B[1;32m--> 132\u001B[0m     grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mravel_pack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss, grads\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\pytorch_minimize\\optim.py:93\u001B[0m, in \u001B[0;36mMinimizeWrapper.ravel_pack\u001B[1;34m(self, tensors)\u001B[0m\n\u001B[0;32m     91\u001B[0m         tensor \u001B[38;5;241m=\u001B[39m tensor\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tensor\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m---> 93\u001B[0m x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([numpyify(tensor)\u001B[38;5;241m.\u001B[39mravel() \u001B[38;5;28;01mfor\u001B[39;00m tensor \u001B[38;5;129;01min\u001B[39;00m tensors], \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     94\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfloatX(x)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\pytorch_minimize\\optim.py:93\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     91\u001B[0m         tensor \u001B[38;5;241m=\u001B[39m tensor\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tensor\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m---> 93\u001B[0m x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([\u001B[43mnumpyify\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mravel() \u001B[38;5;28;01mfor\u001B[39;00m tensor \u001B[38;5;129;01min\u001B[39;00m tensors], \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     94\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfloatX(x)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tedeous\\lib\\site-packages\\pytorch_minimize\\optim.py:90\u001B[0m, in \u001B[0;36mMinimizeWrapper.ravel_pack.<locals>.numpyify\u001B[1;34m(tensor)\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnumpyify\u001B[39m(tensor):\n\u001B[1;32m---> 90\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mtensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m \u001B[38;5;241m!=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     91\u001B[0m         tensor \u001B[38;5;241m=\u001B[39m tensor\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tensor\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(model)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "optimizer.step(closure)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:13:23.682169900Z",
     "start_time": "2023-11-17T08:13:22.895260500Z"
    }
   },
   "id": "6d71f7cc30697e29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "draw_fig(model, grid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T08:13:01.920565Z"
    }
   },
   "id": "e0343ef3a076a1f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T08:13:01.921566100Z"
    }
   },
   "id": "ba1924c96f27c379"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
